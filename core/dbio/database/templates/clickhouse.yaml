core:
  drop_table: drop table if exists {table}
  drop_view: drop view if exists {view}
  create_table: create table {table} ({col_types}) engine=MergeTree {partition_by} ORDER BY tuple()
  create_temporary_table: create table {table} ({col_types}) engine=Memory
  rename_table: ALTER TABLE {table} RENAME TO {new_table}
  alter_columns: alter table {table} modify column {col_ddl}
  modify_column: '{column} {type}'


metadata:

  current_database:
    select currentDatabase()
    
  databases: |
    select currentDatabase() as name
  
  # clickhouse does not have schemas
  # has database and table, for example: database1.table1
  # for our purpose a schema is a database
  schemas: |
    select name as schema_name
    from system.databases
    order by name
    
  tables: |
    select name as table_name
    from system.tables
    where engine not in ('View')
      and database = '{schema}'
    order by name
    
  views: |
    select name as table_name
    from system.tables
    where engine = 'View'
      and database = '{schema}'
    order by name

  columns: |
    select name as column_name, type as data_type
    from system.columns
    where database = '{schema}'
      and table = '{table}'
    order by position

  primary_keys: |
    select 1

  indexes: |
    SELECT 1
  
  columns_full: |
    with tables as (
      select
        database,
        name as table_name,
        engine in ('View') as is_view
      from system.tables
      where database = '{schema}' and name = '{table}'
    )
    select
      cols.database as schema_name,
      cols.table as table_name,
      cols.name as column_name,
      cols.type as data_type,
      cols.position as position
    from system.columns cols
    join tables
      on tables.database = cols.database
      and tables.table_name = cols.table
    order by cols.database, cols.table, cols.position

  schemata: |
    with tables as (
      select
        database,
        name as table_name,
        engine in ('View') as is_view
      from system.tables
      where 1=1
        {{if .schema -}} and database = '{schema}' {{- end}}
        {{if .tables -}} and name in ({tables}) {{- end}}
    )
    select
      cols.database as schema_name,
      cols.table as table_name,
      tables.is_view as is_view,
      cols.name as column_name,
      cols.type as data_type,
      cols.position as position
    from system.columns cols
    join tables
      on tables.database = cols.database
      and tables.table_name = cols.table
    order by cols.database, cols.table, cols.position
  
  ddl_table:
    SHOW CREATE TABLE `{schema}`.`{table}`
  
  ddl_view: |
    SHOW CREATE VIEW `{schema}`.`{table}`
  
  sessions:
    select *
    from pg_stat_activity
    where state = 'active'

  session_terminate:
    select pg_terminate_backend({pid})

analysis:
  field_chars: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field, sum(case when cast({field} as text) ~ '\n' then 1 else 0 end) as cnt_nline, 
      sum(case when cast({field} as text) ~ '\t' then 1 else 0 end) as cnt_tab, 
      sum(case when cast({field} as text) ~ ',' then 1 else 0 end) as cnt_comma, 
      sum(case when cast({field} as text) ~ '"' then 1 else 0 end) as cnt_dquote, 
      min(char_length(cast({field} as text))) as f_min_len, 
      max(char_length(cast({field} as text))) as f_max_len
    from `{schema}`.`{table}`

  field_stat_len: |
    -- field_stat_len {table}
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      '{type}' as type,
      count(*) as tot_cnt,
      min(char_length({field})) as f_min_len,
      max(char_length({field})) as f_max_len
    from `{schema}`.`{table}`

  field_stat_deep: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      count(*) as tot_cnt,
      count({field}) as f_cnt,
      count(*) - count({field}) as f_null_cnt,
      round(100.0 * (count(*) - count({field})) / count(*),1) as f_null_prct,
      count(distinct {field}) as f_dstct_cnt,
      round(100.0 * count(distinct {field}) / count(*),1) as f_dstct_prct,
      count(*) - count(distinct {field}) as f_dup_cnt,
      min({field}) as f_min,
      max({field}) as f_max,
      min(char_length(cast({field} as text))) as f_min_len,
      max(char_length(cast({field} as text))) as f_max_len
    from `{schema}`.`{table}`

  distro_field: |
    with t1 as (
      select
        '{field}'::text as field,
        {field},
        count(*) cnt
      from `{schema}`.`{table}`
      group by {field}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from `{schema}`.`{table}`
    )
    select
      '{table}' as table_nm,
      t1.field,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_group: |
    with t1 as (
      select
        '{field}'::text as field,
        {group_expr} as group_exp,
        {field},        
        count(*) cnt
      from `{schema}`.`{table}`
      group by {field}, {group_expr}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from `{schema}`.`{table}`
    )
    select
      '{table}' as table_nm,
      t1.field,
      t1.group_exp,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_date: |
    with t1 as (
        select
          '{field}'::text as field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          count(*) cnt
        from `{schema}`.`{table}`
        group by extract(year from {field}), extract(month from {field})
        order by extract(year from {field}), extract(month from {field})
      )
      , t2 as (
        select '{field}'::text as field, count(*) ttl_cnt
        from `{schema}`.`{table}`
      )
      select 
        '{schema}' as schema_nm,
        '{table}' as table_nm,
        t1.field,
        t1.year,
        t1.month,
        cnt,
        round(100.0 * cnt / ttl_cnt, 2) as prct
      from t1
      join t2
        on t1.field = t2.field
      order by t1.year, t1.month

function:
  truncate_f: round({field}, 2, 1)
  truncate_datef: CONVERT(DATETIME, CONVERT(DATE, {field}))
  checksum_string: char_length({field})
  checksum_datetime: toUnixTimestamp64Nano(toDateTime64({field}, 6)) / 1000
  # checksum_datetime: toUnixTimestamp64Nano(toDateTime64({field}, 6)) / 1000
  checksum_decimal: ABS(CAST({field} as Nullable(Int64)))


variable:
  # bind_string: "@p{c}"
  batch_rows: 200
  batch_values: 2000
  bool_as: string
  error_filter_table_exists: already
  quote_char: '`'
  timestamp_layout: '2006-01-02 15:04:05.000000 -07'
  timestamp_layout_str: parseDateTime64BestEffortOrNull('{value}')