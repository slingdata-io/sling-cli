core:
  create_table: |
    BEGIN
      EXECUTE IMMEDIATE 'create table {table} ({col_types})';
    EXCEPTION
      WHEN OTHERS THEN
        IF SQLCODE != -955 THEN
          RAISE;
        END IF;
    END;
  drop_table: |
    BEGIN
      EXECUTE IMMEDIATE 'DROP TABLE {table} purge';
    EXCEPTION
      WHEN OTHERS THEN
        IF SQLCODE != -942 THEN
          RAISE;
        END IF;
    END;
  drop_view: |
    BEGIN
      EXECUTE IMMEDIATE 'DROP VIEW {view}';
    EXCEPTION
      WHEN OTHERS THEN
        IF SQLCODE != -942 THEN
          RAISE;
        END IF;
    END;
  drop_index: |
    BEGIN
      EXECUTE IMMEDIATE 'DROP INDEX {index}';
    EXCEPTION
      WHEN OTHERS THEN
          IF SQLCODE != -1418 THEN -- Error code for "index not found"
            RAISE;
          END IF;
    END;
  # create_temporary_table: create global temporary table {table} ({col_types})
  create_index: create index {index} on {table} ({cols})
  insert: INSERT {options} INTO {table} ({fields}) values  ({values})
  alter_columns: alter table {table} modify ({col_ddl})
  insert_all: |
      INSERT ALL
      INTO t (col1, col2, col3) values  ('val1_1', 'val1_2', 'val1_3')
      INTO t (col1, col2, col3) values  ('val2_1', 'val2_2', 'val2_3')
      INTO t (col1, col2, col3) values  ('val3_1', 'val3_2', 'val3_3')
      select 1 from DUAL
  insert_option: /*+ APPEND NOLOGGING */
  sample: select {fields} from {table} SAMPLE(50) where rownum <= {n}
  limit: select {fields} from {table} where rownum <= {limit}{where_and}
  limit_offset: select {fields} from {table}{where_clause} order by 1 offset {offset} rows fetch next {limit} rows only
  limit_sql: select * from ( {sql} ) where rownum <= {limit}
  incremental_select_limit: select {fields} from {table} where rownum <= {limit}{where_and} and ({incremental_where_cond}) order by {update_key} asc
  incremental_select_limit_offset: select {fields} from {table} where rownum <= {limit}{where_and} and ({incremental_where_cond}) order by {update_key} asc offset {offset} rows fetch next {limit} rows only
  replace: |
    merge into {table} tgt
    using (select {name_values}
            from dual) src
    ON ({src_tgt_condition})
    WHEN MATCHED THEN
      UPDATE SET {set_fields}
    WHEN NOT MATCHED THEN
        insert ({names}) values ({values})
  ddl: |
    select to_char(dbms_metadata.get_ddl('{obj_type}','{table}','{schema}')) as ddl
    from dual
  sqlldr: |
    OPTIONS (
      SKIP=1,
      ROWS=1000,
      PARALLEL=true,
      DIRECT=true,
      SKIP_INDEX_MAINTENANCE=true
    )
    LOAD DATA
    INFILE '/dev/stdin'
    APPEND
    INTO TABLE {table}
    FIELDS TERMINATED BY ","
    OPTIONALLY ENCLOSED BY '"'
    TRAILING NULLCOLS
    (
      {columns}
    )
  add_column: alter table {table} add {column} {type}

metadata:
  current_database: select name from V$database
  
  databases: select name from V$database

  schemas: |
    select username as schema_name
    from sys.all_users
    order by username
  
  tables: |
    select owner as schema_name, table_name, 'false' as is_view
    from sys.all_tables
    {{if .schema -}} where owner = '{schema}' {{- end}}
    order by owner, table_name
    
  views: |
    select owner as schema_name, view_name as table_name, 'true' as is_view
    from sys.all_views
    {{if .schema -}} where owner = '{schema}' {{- end}}
    order by owner, view_name

  columns: |
    select column_name, data_type, coalesce(data_precision, data_length) as precision, data_scale as scale
    from sys.all_tab_columns
    where owner = '{schema}'
      and table_name = '{table}'
    order by column_id

  # since joining in above in 'columns` slows things down
  columns_synonym: |
    select
      col.column_name,
      col.data_type,
      coalesce(col.data_precision, col.data_length) as precision,
      col.data_scale as scale
    from sys.all_tab_columns col
    inner join sys.all_synonyms syn
      on syn.table_owner = col.owner
      and syn.table_name = col.table_name
    where syn.owner = '{schema}' and syn.synonym_name = '{table}'
    order by col.column_id

  primary_keys: |
    SELECT
      cons.constraint_name as pk_name,
      cols.position as position,
      cols.column_name as column_name
    from all_constraints cons, all_cons_columns cols
    where cons.owner = '{schema}'
      and cols.table_name = '{table}'
      and cons.constraint_type = 'P'
      and cons.constraint_name = cols.constraint_name
      and cons.owner = cols.owner
    ORDER BY cons.owner, cols.table_name, cols.position


  indexes: |
    select
      index_name,
      column_name
    from all_ind_columns
    where index_owner = '{schema}'
      and table_name = '{table}'
    order by index_name, column_position

  ddl_view: |
    select text as ddl
    from sys.all_views
    where owner = '{schema}'
      and view_name = '{table}'

  ddl_table: |
    select dbms_metadata.get_ddl('TABLE', '{table}', '{schema}') as ddl from dual
  
  columns_full: |
    select
      col.owner as schema_name,
      col.table_name as table_name,
      col.column_name as column_name,
      col.data_type as data_type,
      col.column_id as position
    from sys.all_tab_columns col 
    where owner = '{schema}'
      and table_name = '{table}'
    order by col.owner, col.table_name, col.column_id

  schemata: |
    select
      col.owner as schema_name,
      col.table_name as table_name,
      case
        when views.view_name is null then 'false'
        else 'true'
      end as is_view,
      col.column_name as column_name,
      col.data_type as data_type,
      col.column_id as position
    from sys.all_tab_columns col 
    left join sys.all_views views
      on views.owner = col.owner
      and views.view_name = col.table_name
    where 1=1
      {{if .schema -}} and col.owner = '{schema}' {{- end}}
      {{if .tables -}} and table_name in ({tables}) {{- end}}
    order by col.owner, col.table_name, col.column_id

    ;

    select
      syn.owner as schema_name,
      syn.synonym_name as table_name,
      'false' as is_view,
      col.column_name as column_name,
      col.data_type as data_type,
      col.column_id as position
    from sys.all_tab_columns col
    inner join sys.all_synonyms syn
      on syn.table_owner = col.owner
      and syn.table_name = col.table_name
    where 1=1
      {{if .schema -}} and syn.owner = '{schema}' {{- end}}
      {{if .tables -}} and syn.synonym_name in ({tables}) {{- end}}
    order by syn.owner, syn.synonym_name, col.column_id
  
  sessions:
    select s.sid, s.serial# as serial,
    p.spid, s.username, s.schemaname, 
    s.program, s.terminal, s.osuser
      from v$session s
      join v$process p
        on s.paddr = p.addr
    where s.type != 'BACKGROUND'
  
  session_terminate:
    alter system kill session '{sid}, {serial}'

analysis:
  
  field_stat_deep: |
    -- field_stat_deep {field}
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      '{type}' as type,
      count(*) as tot_cnt,
      count({field}) as f_cnt,
      count(*) - count({field}) as f_null_cnt,
      round((count(*) - count({field})) / count(*)*100,1) as f_null_prct,
      count(distinct {field}) as f_dstct_cnt,
      round(count(distinct {field}) / count(*)*100,1) as f_dstct_prct,
      count(*) - count(distinct {field}) as f_dup_cnt,
      cast(min({field}) as varchar(4000)) as f_min,
      cast(max({field}) as varchar(4000)) as f_max,
      min(length({field})) as f_min_len,
      max(length({field})) as f_max_len
    from "{schema}"."{table}"

  distro_field_date: |
    -- distro_field_date {field}
    with t1 as (
        select
          '{field}' as field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          count(*) cnt
        from "{schema}"."{table}"
        group by extract(year from {field}), extract(month from {field})
        order by extract(year from {field}), extract(month from {field})
      )
      , t2 as (
        select '{field}' as field, count(*) ttl_cnt
        from "{schema}"."{table}"
      )
      select 
        '{schema}' as schema_nm,
        '{table}' as table_nm,
        t1.field,
        t1.year,
        t1.month,
        cnt,
        round(100.0 * cnt / ttl_cnt, 2) as prct
      from t1
      join t2
        on t1.field = t2.field
      order by t1.year, t1.month

  distro_field_date_wide: |
    -- distro_field_date {field}
    select
      '{date_field}' as date_field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          extract(day from {field}) as day,
      {columns_sql}
    from "{schema}"."{table}"
    {where_clause}
    group by extract(year from {field}), extract(month from {field}), extract(day from {field})
    order by extract(year from {field}), extract(month from {field}), extract(day from {field})

routine:
  date_trunc_min_max: |
    select
      {fields}
    from {table}
    where {where}
      (({date_field_trunc} >= date '{min_val}'
      and {date_field_trunc} <= date '{max_val}')
    {or_null})

function:
  truncate_f: trunc({field})
  truncate_datef: trunc({field})
  cast_to_text: 'cast({field} as varchar(4000))'
  str_utf8: convert({field},'US7ASCII','WE8ISO8859P1')
  date_to_int: to_number(to_char({field}, 'j'))
  number_to_int: round({field}, 0)
  checksum_date: cast(((CAST({field} as DATE) - to_date('01-JAN-1970','DD-MON-YYYY')) * 86400 * 1000000) as number(25,6))
  checksum_datetime: cast(((CAST({field} as DATE) - to_date('01-JAN-1970','DD-MON-YYYY')) * 86400 * 1000000) + cast(TO_CHAR({field}, 'FF6') as int) as number(25,6))
  sleep: |
    BEGIN
      sys.DBMS_LOCK.sleep({seconds});
    END;

# extra variables
variable:
  column_upper: true
  bool_as: string
  error_ignore_drop_table: "ORA-00942"
  error_ignore_drop_view: "ORA-00942"
  bind_string: ":{field}{n}"
  batch_rows: 20
  date_layout_str: TO_DATE('{value}', 'YYYY-MM-DD HH24:MI:SS') # DATE in oracle has a time component
  timestamp_layout_str: TO_TIMESTAMP('{value}', 'YYYY-MM-DD HH24:MI:SS.FF6')
  timestampz_layout: "2006-01-02 15:04:05.000000 -07:00"
  timestampz_layout_str: TO_TIMESTAMP_TZ('{value}', 'YYYY-MM-DD HH24:MI:SS.FF6 TZH:TZM')
  max_string_type: varchar(4000)
  max_string_length: 4000
  max_column_length: 128

native_type_map:
  bfile: binary
  blob: text
  char: string
  clob: text
  date: datetime
  datetime: datetime
  float: float
  json: json
  long: string
  longvarchar: string
  mlslabel: string
  nchar: string
  nclob: text
  number: decimal
  nvarchar2: string
  raw: binary
  rowid: bigint
  timestamp: timestamp
  timestampdty: timestamp
  timestamptz: timestampz
  timestamptz_dty: timestampz
  varchar2: string

general_type_map:
  bigint: "number(19)"
  binary: "varbinary()"
  bool: "varchar(5)"
  date: date
  datetime: "timestamp(9)"
  decimal: "number(,)"
  float: number
  integer: "number(10)"
  json: clob
  smallint: "number(5)"
  string: "varchar()"
  text: clob
  time: "varchar()"
  timestamp: "timestamp(9)"
  timestampz: "timestamp(9) with time zone"
  timez: "varchar()"
  uuid: "varchar(36)"
