core:
  create_table: |
    create table {table} (
      {col_types}
    ) 
    location '{location}'
    tblproperties (
      'table_type'='iceberg',
      'compression_level'='3',
      'format'='PARQUET',
      'write_compression'='ZSTD'
    )
    {partition_by}
    {bucket_by}
  create_table_external: |
    create external table {table} (
      {col_types}
    )
    stored as parquet
    location '{location}'
  drop_table: drop table if exists {table} purge
  drop_view: drop view if exists {view}
  drop_index: "select 'indexes do not apply for Athena'"
  create_index: "select 'indexes do not apply for Athena'"
  sample: select {fields} from {table} tablesample bernoulli (5) limit {n}
  rename_table: alter table {table} rename to {new_table}
  set_schema: |
    -- Athena doesn't support changing schema with ALTER, need to recreate
    create table {new_schema}.{table} as
    select * from {table};
    drop table {table}
  
  # does not allow timestamp(6), only timestamp(3)
  unload_to_s3: |
    unload ({sql})
    to '{s3_path}'
    with (
      format = 'PARQUET',
      compression = 'SNAPPY'
    )

  # using CREATE TABLE AS SELECT (CTAS) instead of UNLOAD, allows timestamp(6)
  unload_to_s3_ctas: |
    CREATE TABLE {table} 
    WITH (
        format = 'PARQUET',
        write_compression = 'SNAPPY',
        external_location = '{s3_path}'
    )
    AS
    {sql}

  alter_columns: |
    -- Athena requires recreating the table to change column definitions
    -- This is a placeholder, actual implementation requires multiple steps
    -- ALTER TABLE {table} {col_ddl}
    select 'alter column not directly supported in Athena, must recreate table'
 
metadata:
  current_database:
    select current_database
    
  databases: |
    select 'catalog' as name
    
  schemas: |
    select schema_name
    from information_schema.schemata
    order by schema_name
    
  tables: |
    select 
      table_schema as schema_name, 
      table_name, 
      case 
        when table_type = 'VIEW' THEN 'true'
        else 'false'
      end as is_view
    from information_schema.tables
    where table_type = 'BASE TABLE'
      {{if .schema -}} and table_schema = '{schema}' {{- end}}
    order by table_schema, table_name
    
  views: |
    select 
      table_schema as schema_name, 
      table_name, 
      'true' as is_view
    from information_schema.tables
    where table_type = 'VIEW'
      {{if .schema -}} and table_schema = '{schema}' {{- end}}
    order by table_schema, table_name

  columns: |
    select column_name, data_type
    from information_schema.columns
    where table_schema = '{schema}'
      and table_name = '{table}'
    order by ordinal_position

  primary_keys: |
    -- Athena doesn't track primary keys in information_schema
    -- This is a placeholder query that will return no results
    select 
      '' as pk_name,
      0 as position,
      '' as column_name
    where false

  indexes: |
    -- Athena doesn't support indexes, return empty result
    select 
      '' as index_name,
      '' as column_name
    where false 
  
  columns_full: |
    select
      table_schema as schema_name,
        table_name,
      column_name,
      data_type,
      ordinal_position as position
    from information_schema.columns
    where table_schema = '{schema}' 
      and table_name = '{table}'
    order by ordinal_position

  schemata: |
    select
      cols.table_schema as schema_name,
      cols.table_name,
      case 
        when tabs.table_type = 'VIEW' THEN true
        else false
      end as is_view,
      cols.column_name,
      cols.data_type,
      cols.ordinal_position as position
    from information_schema.columns cols
    join information_schema.tables tabs
      on tabs.table_schema = cols.table_schema
      and tabs.table_name = cols.table_name
    where 1=1
      {{if .schema -}} and cols.table_schema = '{schema}' {{- end}}
      {{if .tables -}} and cols.table_name IN ({tables}) {{- end}}
    order by cols.table_schema, cols.table_name, cols.ordinal_position
  
  ddl_table: |
    -- Athena doesn't provide a direct way to get DDL
    -- You can use SHOW CREATE TABLE instead
      select
      'SHOW CREATE TABLE {schema}.{table}' as ddl
    
  ddl_view: |
    -- Athena doesn't provide a direct way to get view definition
    -- You can use SHOW CREATE VIEW instead
    select 
      'SHOW CREATE VIEW {schema}.{table}' as ddl

analysis:
  field_chars: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field, 
      SUM(case when REGEXP_LIKE(CAST({field} AS VARCHAR), '\n') THEN 1 else 0 end) as cnt_nline, 
      SUM(case when REGEXP_LIKE(CAST({field} AS VARCHAR), '\t') THEN 1 else 0 end) as cnt_tab, 
      SUM(case when REGEXP_LIKE(CAST({field} AS VARCHAR), ',') THEN 1 else 0 end) as cnt_comma, 
      SUM(case when REGEXP_LIKE(CAST({field} AS VARCHAR), '"') THEN 1 else 0 end) as cnt_dquote, 
      MIN(LENGTH(CAST({field} AS VARCHAR))) as f_min_len, 
      MAX(LENGTH(CAST({field} AS VARCHAR))) as f_max_len
    from "{schema}"."{table}"

  field_stat_len: |
    -- field_stat_len {table}
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      COUNT(*) as tot_cnt,
      MIN(LENGTH(CAST({field} AS VARCHAR))) as f_min_len,
      MAX(LENGTH(CAST({field} AS VARCHAR))) as f_max_len
    from "{schema}"."{table}"
  
  field_stat_deep: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      COUNT(*) as tot_cnt,
      COUNT({field}) as f_cnt,
      COUNT(*) - COUNT({field}) as f_null_cnt,
      ROUND(100.0 * (COUNT(*) - COUNT({field})) / COUNT(*), 1) as f_null_prct,
      COUNT(DISTINCT {field}) as f_dstct_cnt,
      ROUND(100.0 * COUNT(DISTINCT {field}) / COUNT(*), 1) as f_dstct_prct,
      COUNT(*) - COUNT(DISTINCT {field}) as f_dup_cnt,
      CAST(MIN({field}) AS VARCHAR) as f_min,
      CAST(MAX({field}) AS VARCHAR) as f_max,
      MIN(LENGTH(CAST({field} AS VARCHAR))) as f_min_len,
      MAX(LENGTH(CAST({field} AS VARCHAR))) as f_max_len
    from "{schema}"."{table}"

  distro_field: |
    WITH t1 AS (
      select
        '{field}' as field,
        {field},
        COUNT(*) cnt
      from "{schema}"."{table}"
      GROUP BY {field}
      order by COUNT(*) DESC
    ),
    t2 AS (
      select
        '{field}' as field,
        COUNT(*) ttl_cnt
      from "{schema}"."{table}"
    )
    select
      '{table}' as table_nm,
      t1.field,
      {field} as value,
      cnt,
      ROUND(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt DESC

  distro_field_group: |
    WITH t1 AS (
      select
        '{field}' as field,
        {group_expr} as group_exp,
        {field},        
        COUNT(*) cnt
      from "{schema}"."{table}"
      GROUP BY {field}, {group_expr}
      order by COUNT(*) DESC
    ),
    t2 AS (
      select
        '{field}' as field,
        COUNT(*) ttl_cnt
      from "{schema}"."{table}"
    )
    select
      '{table}' as table_nm,
      t1.field,
      t1.group_exp,
      {field} as value,
      cnt,
      ROUND(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt DESC

  distro_field_date: |
    WITH t1 AS (
      select
        '{field}' as field,
        EXTRACT(year from {field}) as year,
        EXTRACT(month from {field}) as month,
        EXTRACT(day from {field}) as day,
        COUNT(*) cnt
      from "{schema}"."{table}"
      GROUP BY 
        EXTRACT(year from {field}), 
        EXTRACT(month from {field}), 
        EXTRACT(day from {field})
      order by 
        EXTRACT(year from {field}), 
        EXTRACT(month from {field}), 
        EXTRACT(day from {field})
    ),
    t2 AS (
      select 
        '{field}' as field, 
        COUNT(*) ttl_cnt
      from "{schema}"."{table}"
    )
    select 
        '{schema}' as schema_nm,
        '{table}' as table_nm,
        t1.field,
        t1.year,
        t1.month,
        t1.day,
        cnt,
      ROUND(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by t1.year, t1.month, t1.day

function:
  truncate_f: CAST({field} AS INTEGER)
  truncate_datef: DATE_TRUNC('day', {field})
  string_type: VARCHAR
  cast_to_string: CAST({field} AS VARCHAR)
  cast_to_text: CAST({field} AS VARCHAR)
  date_to_int: CAST(DATE_DIFF('day', DATE '1970-01-01', {field}) AS INTEGER)
  number_to_int: CAST(ROUND({field}, 0) AS INTEGER)
  checksum_date: DATE_DIFF('second', TIMESTAMP '1970-01-01 00:00:00', CAST({field} AS TIMESTAMP))
  checksum_datetime: DATE_DIFF('second', TIMESTAMP '1970-01-01 00:00:00', CAST({field} AS TIMESTAMP))
  checksum_string: LENGTH(CAST({field} AS VARCHAR))
  checksum_integer: ABS({field})
  checksum_decimal: CAST(ROUND(ABS({field}) * 1000000, 0) AS BIGINT)
  checksum_boolean: LENGTH(case when {field} = true THEN 'true' when {field} = false THEN 'false' end)
  checksum_json: LENGTH(REGEXP_REPLACE(CAST({field} AS VARCHAR), ' ', ''))
  now: CURRENT_TIMESTAMP

variable:
  quote_char: '`'
  max_string_type: VARCHAR
  max_string_length: 2147483647
  max_column_length: 127