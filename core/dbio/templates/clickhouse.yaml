core:
  drop_table: drop table if exists {table}
  drop_view: drop view if exists {view}
  drop_index: "select 'indexes not implemented for clickhouse'"
  create_index: "select 'indexes not implemented for clickhouse'"
  create_schema: create database {schema}
  create_table: create table if not exists {table} ({col_types}) engine=MergeTree {primary_key} {partition_by} ORDER BY {order_by}
  rename_table: ALTER TABLE {table} RENAME TO {new_table}
  alter_columns: alter table {table} modify column {col_ddl}
  modify_column: '{column} {type}'
  update: alter table {table} update {set_fields} where {pk_fields_equal}
  delete_where_not_exist: |
    alter table {target_table}
    delete where {where}
      and {unique_id} not in (
        select {unique_id}
        from {temp_table}
      )
  update_where_not_exist: |
    alter table {target_table}
    update {set_fields}
    where {where}
      and {unique_id} not in (
        select {unique_id}
        from {temp_table}
      )

  # ClickHouse only supports insert and delete_insert
  merge_insert: |
    INSERT INTO {tgt_table} ({insert_fields})
    SELECT {src_fields} FROM {src_table} src

  merge_delete_insert: |
    ALTER TABLE {tgt_table} DELETE
    WHERE ({tgt_pk_fields}) IN (
      SELECT {src_pk_fields} FROM {src_table}
    );
    INSERT INTO {tgt_table} ({insert_fields})
    SELECT {src_fields} FROM {src_table} src

  # ClickHouse does not support UPDATE or UPDATE_INSERT (no native MERGE statement)
  merge_update: null
  merge_update_insert: null

  # ClickHouse does NOT support foreign keys - this template will not be used
  # add_foreign_key: null

  # Column comment/description template (ClickHouse uses COMMENT COLUMN syntax)
  add_column_comment: ALTER TABLE {table} COMMENT COLUMN `{column}` {comment}

  # Table comment/description template (ClickHouse uses MODIFY COMMENT)
  add_table_comment: ALTER TABLE {table} MODIFY COMMENT {comment}

metadata:

  current_database:
    select currentDatabase()
    
  databases: |
    select currentDatabase() as name
  
  # clickhouse does not have schemas
  # has database and table, for example: database1.table1
  # for our purpose a schema is a database
  schemas: |
    select name as schema_name
    from system.databases
    order by name
    
  tables: |
    select database as schema_name, name as table_name, 'false' as is_view
    from system.tables
    where engine not in ('View')
      {{if .schema -}} and database = '{schema}' {{- end}}
    order by database, name
    
  views: |
    select database as schema_name, name as table_name, 'true' as is_view
    from system.tables
    where engine = 'View'
      {{if .schema -}} and database = '{schema}' {{- end}}
    order by database, name

  columns: |
    select name as column_name, type as data_type
    from system.columns
    where database = '{schema}'
      and table = '{table}'
    order by position

  # Extract primary key columns from system.tables
  primary_keys: |
    SELECT
      'PRIMARY' AS pk_name,
      arrayJoin(splitByChar(',', replaceRegexpAll(primary_key, ' ', ''))) AS column_name,
      rowNumberInAllBlocks() + 1 AS position
    FROM system.tables
    WHERE database = '{schema}' AND name = '{table}' AND primary_key != ''

  # ClickHouse data-skipping indexes (not traditional B-tree indexes)
  # Return empty result for now since these are specialized indexes
  indexes: |
    SELECT
      '' AS index_name,
      '' AS column_name
    WHERE 0
  
  columns_full: |
    with tables as (
      select
        database,
        name as table_name,
        engine in ('View') as is_view
      from system.tables
      where database = '{schema}' and name = '{table}'
    )
    select
      cols.database as schema_name,
      cols.table as table_name,
      cols.name as column_name,
      cols.type as data_type,
      cols.position as position
    from system.columns cols
    join tables
      on tables.database = cols.database
      and tables.table_name = cols.table
    order by cols.database, cols.table, cols.position

  schemata: |
    with tables as (
      select
        database,
        name as table_name,
        engine in ('View') as is_view
      from system.tables
      where 1=1
        {{if .schema -}} and database = '{schema}' {{- end}}
        {{if .tables -}} and name in ({tables}) {{- end}}
    )
    select
      cols.database as schema_name,
      cols.table as table_name,
      tables.is_view as is_view,
      cols.name as column_name,
      cols.type as data_type,
      cols.position as position
    from system.columns cols
    join tables
      on tables.database = cols.database
      and tables.table_name = cols.table
    order by cols.database, cols.table, cols.position
  
  ddl_table:
    SHOW CREATE TABLE `{schema}`.`{table}`
  
  ddl_view: |
    SHOW CREATE VIEW `{schema}`.`{table}`
  
  sessions:
    select *
    from pg_stat_activity
    where state = 'active'

  session_terminate:
    select pg_terminate_backend({pid})

  # Extended column attributes for schema migration
  # Note: ClickHouse does not support IDENTITY or FK constraints
  # Uses system.tables to detect primary key columns
  columns_extended: |
    SELECT
      c.name AS column_name,
      CASE WHEN startsWith(c.type, 'Nullable') THEN 'true' ELSE 'false' END AS is_nullable,
      c.default_expression AS default_value,
      'false' AS is_auto_increment,
      NULL AS identity_seed,
      NULL AS identity_increment,
      CASE
        WHEN has(splitByChar(',', replaceRegexpAll(t.primary_key, ' ', '')), c.name)
        THEN 'true'
        ELSE 'false'
      END AS is_primary_key,
      c.comment AS description
    FROM system.columns c
    JOIN system.tables t ON t.database = c.database AND t.name = c.table
    WHERE c.database = '{schema}' AND c.table = '{table}'
    ORDER BY c.position

  # ClickHouse does NOT support foreign keys
  # This query returns no rows, which is the correct behavior
  foreign_keys: |
    SELECT
      '' AS constraint_name,
      '' AS column_name,
      '' AS referenced_schema,
      '' AS referenced_table,
      '' AS referenced_column,
      '' AS on_delete,
      '' AS on_update
    WHERE 1=0

  # Extended table attributes for schema migration
  table_extended: |
    SELECT comment AS description
    FROM system.tables
    WHERE database = '{schema}' AND name = '{table}'

analysis:
  field_chars: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field, sum(case when cast({field} as text) ~ '\n' then 1 else 0 end) as cnt_nline, 
      sum(case when cast({field} as text) ~ '\t' then 1 else 0 end) as cnt_tab, 
      sum(case when cast({field} as text) ~ ',' then 1 else 0 end) as cnt_comma, 
      sum(case when cast({field} as text) ~ '"' then 1 else 0 end) as cnt_dquote, 
      min(char_length(cast({field} as text))) as f_min_len, 
      max(char_length(cast({field} as text))) as f_max_len
    from `{schema}`.`{table}`

  field_stat_len: |
    -- field_stat_len {table}
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      '{type}' as type,
      count(*) as tot_cnt,
      min(char_length({field})) as f_min_len,
      max(char_length({field})) as f_max_len
    from `{schema}`.`{table}`

  field_stat_deep: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      count(*) as tot_cnt,
      count({field}) as f_cnt,
      count(*) - count({field}) as f_null_cnt,
      round(100.0 * (count(*) - count({field})) / count(*),1) as f_null_prct,
      count(distinct {field}) as f_dstct_cnt,
      round(100.0 * count(distinct {field}) / count(*),1) as f_dstct_prct,
      count(*) - count(distinct {field}) as f_dup_cnt,
      min({field}) as f_min,
      max({field}) as f_max,
      min(char_length(cast({field} as text))) as f_min_len,
      max(char_length(cast({field} as text))) as f_max_len
    from `{schema}`.`{table}`

  distro_field: |
    with t1 as (
      select
        '{field}'::text as field,
        {field},
        count(*) cnt
      from `{schema}`.`{table}`
      group by {field}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from `{schema}`.`{table}`
    )
    select
      '{table}' as table_nm,
      t1.field,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_group: |
    with t1 as (
      select
        '{field}'::text as field,
        {group_expr} as group_exp,
        {field},        
        count(*) cnt
      from `{schema}`.`{table}`
      group by {field}, {group_expr}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from `{schema}`.`{table}`
    )
    select
      '{table}' as table_nm,
      t1.field,
      t1.group_exp,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_date: |
    with t1 as (
        select
          '{field}'::text as field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          count(*) cnt
        from `{schema}`.`{table}`
        group by extract(year from {field}), extract(month from {field})
        order by extract(year from {field}), extract(month from {field})
      )
      , t2 as (
        select '{field}'::text as field, count(*) ttl_cnt
        from `{schema}`.`{table}`
      )
      select 
        '{schema}' as schema_nm,
        '{table}' as table_nm,
        t1.field,
        t1.year,
        t1.month,
        cnt,
        round(100.0 * cnt / ttl_cnt, 2) as prct
      from t1
      join t2
        on t1.field = t2.field
      order by t1.year, t1.month

function:
  truncate_f: round({field}, 2, 1)
  truncate_datef: CONVERT(DATETIME, CONVERT(DATE, {field}))
  checksum_string: char_length({field})
  checksum_datetime: toUnixTimestamp64Nano(toDateTime64({field}, 6)) / 1000
  # checksum_datetime: toUnixTimestamp64Nano(toDateTime64({field}, 6)) / 1000
  checksum_decimal: ABS(CAST({field} as Nullable(Int64)))
  checksum_boolean: length(case when {field} is null then '' when {field} > 0 then 'true' else 'false' end)
  now: now()
  cast_to_string: 'toString({field})'


variable:
  # ClickHouse default is delete_insert since it doesn't support native MERGE
  default_merge_strategy: delete_insert
  # bind_string: "@p{c}"
  batch_rows: 200
  batch_values: 2000
  bool_as: integer
  error_filter_table_exists: already
  quote_char: '`'
  timestamp_layout: '2006-01-02 15:04:05.000000000 -07'
  timestamp_layout_str: parseDateTime64BestEffortOrNull('{value}')
  max_string_type: String
  max_string_length: 1000000000
  max_column_length: 256

native_type_map:
  array: json
  bool: bool
  date: date
  datetime: datetime
  datetime64: datetime
  decimal: decimal
  enum: string
  enum8: string
  fixedstring: text
  float32: float
  float64: float
  int16: smallint
  int32: integer
  int64: bigint
  int8: smallint
  ipv6: string
  json: json
  lowcardinality: string
  map: json
  simpleaggregatefunction: text
  string: text
  tuple: string
  uint16: integer
  uint32: bigint
  uint64: "decimal(28,0)"
  uint8: integer
  uuid: uuid

general_type_map:
  bigint: "Nullable(Int64)"
  binary: "Nullable(String)"
  bool: "Nullable(Bool)"
  date: "Nullable(Date)"
  datetime: "Nullable(DateTime64(6))"
  decimal: "Nullable(Decimal(,))"
  float: "Nullable(Float64)"
  integer: "Nullable(Int64)"
  json: "Nullable(String)"
  smallint: "Nullable(Int32)"
  string: "Nullable(String)"
  text: "Nullable(String)"
  time: "Nullable(String)"
  timestamp: "Nullable(DateTime64(6))"
  timestampz: "Nullable(DateTime64(6))"
  timez: "Nullable(String)"
  uuid: "Nullable(UUID)"

# Schema migration: default value translation between native and generalized forms
default_value_map:
  to_general:
    "now()": "current_timestamp"
    "NOW()": "current_timestamp"
    "today()": "current_date"
    "TODAY()": "current_date"
    "generateUUIDv4()": "uuid()"
    "1": "true"
    "0": "false"
  from_general:
    "current_timestamp": "now()"
    "current_timestamp_utc": "now()"
    "current_date": "today()"
    "current_time": "now()"
    "uuid()": "generateUUIDv4()"
    "true": "1"
    "false": "0"
    "null": "NULL"
