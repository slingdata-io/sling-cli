core:
  drop_table: drop table if exists {table}
  drop_view: drop view if exists {view}
  create_table: create table if not exists {table} ({col_types})
  create_unique_index: create unique index if not exists {index} on {table} ({cols})
  replace: insert into {table} ({fields}) values ({values}) on conflict ({pk_fields}) do update set {set_fields}
  replace_temp: |
    insert into {table} ({names})
    select {names} from {temp_table}
    on conflict ({pk_fields}) do nothing;
    update {table} as t1 set {set_fields2}
    from (select * from {temp_table}) as t2
    where {pk_fields_equal}
  insert: insert into {table} ({fields}) values ({values})
  limit: select {fields} from {table} offset {offset} limit {limit}
  limit_sql: |
    select * from (
      {sql}
    ) as t offset {offset} limit {limit}
  insert_temp: insert into {table} ({fields}) select {cols} from {temp_table}
  insert_ignore: insert into {table} ({fields}) values ({values}) on conflict ({pk_fields}) do nothing
  insert_ignore_temp: insert into {table} ({names}) select {names} from {temp_table} on conflict ({pk_fields}) do nothing
  update_temp: |
    update {table} as t1 set {set_fields2}
    from (select * from {temp_table}) as t2
    where {pk_fields_equal2}
  sample: select {fields} from {table} TABLESAMPLE SYSTEM (50) limit {n}
  rename_table: ALTER TABLE {table} RENAME TO {new_table}
  modify_column: alter column {column} type {type}
  use_database: SET SESSION catalog.name = {database}

metadata:

  current_database:
    
  databases: 
    
  schemas: |
    select schema_name
    from information_schema.schemata
    order by schema_name
    
  tables: |
    select table_schema as schema_name, table_name, 'false' as is_view
    from information_schema.tables
    where table_type = 'BASE TABLE'
      {{if .schema -}} and table_schema = '{schema}' {{- end}}
    order by table_schema, table_name
    
  views: |
    select table_schema as schema_name, table_name, 'true' as is_view
    from information_schema.tables
    where table_type = 'VIEW'
      {{if .schema -}} and table_schema = '{schema}' {{- end}}
    order by table_schema, table_name

  columns: |
    select column_name, data_type
    from information_schema.columns
    where table_schema = '{schema}'
      and table_name = '{table}'
    order by ordinal_position

  primary_keys: |
    select tco.constraint_name as pk_name,
           kcu.ordinal_position as position,
           kcu.column_name as column_name
    from information_schema.table_constraints tco
    join information_schema.key_column_usage kcu 
         on kcu.constraint_name = tco.constraint_name
         and kcu.constraint_schema = tco.constraint_schema
         and kcu.constraint_name = tco.constraint_name
    where kcu.table_schema = '{schema}'
      and kcu.table_name = '{table}'
    order by kcu.table_schema,
             kcu.table_name,
             position

  indexes:

  columns_full: |
    with tables as (
      select
        table_catalog,
        table_schema,
        table_name,
        case table_type
          when 'VIEW' then 'true'
          else 'false'
        end as is_view
      from information_schema.tables
      where table_schema = '{schema}' and table_name = '{table}'
    )
    select
      cols.table_schema as schema_name,
      cols.table_name as table_name,
      cols.column_name as column_name,
      cols.data_type as data_type,
      cols.ordinal_position as position
    from information_schema.columns cols
    join tables
      on tables.table_catalog = cols.table_catalog
      and tables.table_schema = cols.table_schema
      and tables.table_name = cols.table_name
    order by cols.table_catalog, cols.table_schema, cols.table_name, cols.ordinal_position

  schemata: |
    with tables as (
      select
        table_catalog,
        table_schema,
        table_name,
        case table_type
          when 'VIEW' then 'true'
          else 'false'
        end as is_view
      from information_schema.tables
      where 1=1
        {{if .schema -}} and table_schema = '{schema}' {{- end}}
        {{if .tables -}} and table_name in ({tables}) {{- end}}
    )
    select
      cols.table_schema as schema_name,
      cols.table_name as table_name,
      tables.is_view as is_view,
      cols.column_name as column_name,
      cols.data_type as data_type,
      cols.ordinal_position as position
    from information_schema.columns cols
    join tables
      on tables.table_catalog = cols.table_catalog
      and tables.table_schema = cols.table_schema
      and tables.table_name = cols.table_name
    order by cols.table_catalog, cols.table_schema, cols.table_name, cols.ordinal_position
  
  row_count_estimates: |
    select 
      nspname as schema_name,
      relname as table_name,
      reltuples as count
    from pg_class c
    left join pg_namespace n on (n.oid = c.relnamespace)
    where nspname not in ('pg_catalog', 'information_schema', '_timescaledb_internal')
      and relkind = 'r' 
      {{if .schema -}} and nspname = '{schema}' {{- end}}
      {{if .table -}} and relnam = '{table}' {{- end}}
    order by reltuples desc

  ddl_table: "
    with tabledefinition as (
    SELECT
    n.nspname, c.relname, a.attname AS column_name,
    pg_catalog.format_type(a.atttypid, a.atttypmod) as type,
    case
    when a.attnotnull
    then 'NOT NULL'
    else 'NULL'
    END as not_null
    from pg_class c,
    pg_attribute a,
    pg_type t,
    pg_namespace n
    where  n.nspname = '{schema}' and c.relname = '{table}'
    AND a.attnum > 0
    AND a.attrelid = c.oid
    AND a.atttypid = t.oid
    and  n.oid = c.relnamespace
    ORDER BY a.attnum
    )
    , table_ddl as (
    SELECT
    'CREATE TABLE ' || nspname || '.' || relname || E'\n(\n' ||
    array_to_string(
    array_agg(
    '    \"' || column_name || '\" ' ||  type || ' '|| not_null
    )
    , E',\n'
    ) || E'\n)' as ddl
    from tabledefinition
    group by nspname, relname
    )
    select
    table_ddl.ddl as ddl
    from table_ddl
    "
  ddl_view: |
    select pg_get_viewdef(to_regclass('"{schema}"."{table}"'))::text as ddl

  sessions: select *
    from pg_stat_activity
    where state = 'active'

  session_terminate: select pg_terminate_backend({pid})

analysis:
  field_chars: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field, sum(case when {field}::text ~ '\n' then 1 else 0 end) as cnt_nline, 
      sum(case when {field}::text ~ '\t' then 1 else 0 end) as cnt_tab, 
      sum(case when {field}::text ~ ',' then 1 else 0 end) as cnt_comma, 
      sum(case when {field}::text ~ '"' then 1 else 0 end) as cnt_dquote, 
      min(length({field}::text)) as f_min_len, 
      max(length({field}::text)) as f_max_len
    from "{schema}"."{table}"

  field_stat_len: |
    -- field_stat_len {field}
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      count(*) as tot_cnt,
      -- max(length(abs(({field} - round({field},0)))::text)-2) as f_max_dec_len,
      min(length({field}::text)) as f_min_len,
      max(length({field}::text)) as f_max_len
    from "{schema}"."{table}"

  field_stat_deep: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      count(*) as tot_cnt,
      count({field}) as f_cnt,
      count(*) - count({field}) as f_null_cnt,
      round(100.0 * (count(*) - count({field})) / count(*),1) as f_null_prct,
      count(distinct {field}) as f_dstct_cnt,
      round(100.0 * count(distinct {field}) / count(*),1) as f_dstct_prct,
      count(*) - count(distinct {field}) as f_dup_cnt,
      min({field})::text as f_min,
      max({field})::text as f_max,
      min(length({field}::text)) as f_min_len,
      max(length({field}::text)) as f_max_len
    from "{schema}"."{table}"

  distro_field: |
    with t1 as (
      select
        '{field}'::text as field,
        {field},
        count(*) cnt
      from "{schema}"."{table}"
      group by {field}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from "{schema}"."{table}"
    )
    select
      '{table}' as table_nm,
      t1.field,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_group: |
    with t1 as (
      select
        '{field}'::text as field,
        {group_expr} as group_exp,
        {field},        
        count(*) cnt
      from "{schema}"."{table}"
      group by {field}, {group_expr}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from "{schema}"."{table}"
    )
    select
      '{table}' as table_nm,
      t1.field,
      t1.group_exp,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_date: |
    with t1 as (
        select
          '{field}'::text as field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          extract(day from {field}) as day,
          count(*) cnt
        from "{schema}"."{table}"
        group by 2, 3, 4
        order by 2, 3, 4
      )
      , t2 as (
        select '{field}'::text as field, count(*) ttl_cnt
        from "{schema}"."{table}"
      )
      select 
        '{schema}' as schema_nm,
        '{table}' as table_nm,
        t1.field,
        t1.year,
        t1.month,
        t1.day,
        cnt,
        round(100.0 * cnt / ttl_cnt, 2) as prct
      from t1
      join t2
        on t1.field = t2.field
      order by t1.year, t1.month, t1.day

function:
  truncate_f: trunc({field})
  truncate_datef: trunc({field})
  string_type: text
  checksum_boolean: length(cast({field} as varchar))
  checksum_decimal: ABS(truncate({field}))
  checksum_datetime: to_unixtime({field}) * 1000000

variable:
  tmp_folder: /tmp
  bind_string: '?'
  error_filter_table_exists: already exists
  max_string_type: varchar
  max_string_length: 1000000

native_type_map:
  bigint: bigint
  boolean: bool
  date: date
  decimal: decimal
  double: float
  integer: integer
  json: json
  smallint: smallint
  text: text
  timestamp: timestamp
  "timestamp with time zone": timestampz
  unknown: text
  varbinary: binary
  varchar: string

general_type_map:
  bigint: bigint
  binary: varbinary
  bool: boolean
  date: date
  datetime: timestamp
  decimal: "decimal(,)"
  float: double
  integer: integer
  json: json
  smallint: smallint
  string: varchar
  text: varchar
  time: varchar
  timestamp: timestamp
  timestampz: "timestamp with time zone"
  timez: varchar
  uuid: uuid
