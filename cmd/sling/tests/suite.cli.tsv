n	test_name	rows	bytes	streams	fails	output_contains	command
1	Simple sling command					Slings data from a data source to a data target.	sling
2	Run sling command					Execute a run	sling run
3	Run sling with Excel source	1317				wrote 1317 rows	sling run --src-stream file://core/dbio/filesys/test/test.excel2.xlsx --tgt-object file://test.xlsx
4	Run sling with CSV source and POSTGRES target	18					cat cmd/sling/tests/files/test1.1.csv | sling run --tgt-conn POSTGRES --tgt-object public.my_table --mode full-refresh
5	Run sling with CSV source and POSTGRES target	18					sling run --src-stream file://cmd/sling/tests/files/test1.1.csv --tgt-conn POSTGRES --tgt-object public.my_table --mode full-refresh
6	Run sling with CSV source and MSSQL target	18					sling run --src-stream file://cmd/sling/tests/files/test1.1.csv --tgt-conn MSSQL --tgt-object dbo.my_table --mode full-refresh --tgt-options 'use_bulk: false'
7	Run sling with CSV source and custom options	4					"sling run --src-stream file://cmd/sling/tests/files/test4.csv --src-options '{ delimiter: ""|"", escape: ""\\"" }' --stdout > /dev/null"
8	Run sling with gzipped CSV source and POSTGRES target	18					cat cmd/sling/tests/files/test1.1.csv.gz | sling run --tgt-conn POSTGRES --tgt-object public.my_table1 --mode full-refresh
9	Run sling with gzipped CSV source and MYSQL target	18					sling run --src-stream 'file://cmd/sling/tests/files/test1.1.csv.gz' --tgt-conn MYSQL --tgt-object mysql.my_table --mode full-refresh --tgt-options 'use_bulk: false'
10	Run sling with JSON source and POSTGRES target	1					"cat cmd/sling/tests/files/test3.json | sling run --src-options ""flatten: true"" --tgt-conn POSTGRES --tgt-object public.my_table2 --tgt-options 'use_bulk: false' --mode full-refresh"
11	Run sling with JSON source and POSTGRES target	1					"sling run --src-stream 'file://cmd/sling/tests/files/test3.json'  --src-options ""flatten: true"" --tgt-conn POSTGRES --tgt-object public.my_table3 --tgt-options 'use_bulk: false' --mode full-refresh"
12	Run sling with CSV source and no header	2					sling run --src-stream 'file://cmd/sling/tests/files/test6.csv' --stdout -d --src-options '{ header: false }' > /dev/null
13	Run sling with echo input and empty allowed	0	6			execution succeeded	echo 'a,b,c' | SLING_ALLOW_EMPTY=true sling  run --tgt-object file:///tmp/test.csv
14	Run sling with POSTGRES source and CSV output	18					sling run --src-conn POSTGRES --src-stream public.my_table --stdout > /tmp/my_table.csv
15	Run sling with POSTGRES source and CSV target	18					sling run --src-conn POSTGRES --src-stream public.my_table --tgt-object file:///tmp/my_table.csv
16	Run sling with POSTGRES source and select columns	2				id,email	sling run --src-conn POSTGRES --src-stream public.my_table --stdout --select 'id,email' -l 2
17	Run sling with POSTGRES source and exclude columns	2				first_name,last_name,email,target,create_dt	sling run --src-conn POSTGRES --src-stream public.my_table --stdout --select '-id' -l 2
18	Run sling with gzipped CSV source and POSTGRES target with ignore existing	0				execution succeeded	cat cmd/sling/tests/files/test1.1.csv.gz | sling run --tgt-conn POSTGRES --tgt-object public.my_table --mode full-refresh --tgt-options 'ignore_existing: true'
19	Run sling with POSTGRES source and CSV target with ignore existing	0				execution succeeded	sling run --src-conn POSTGRES --src-stream public.my_table --tgt-object file:///tmp/my_table.csv --tgt-options 'ignore_existing: true'
20	Run sling with binary CSV source and POSTGRES target	1					sling run --src-stream file://cmd/sling/tests/files/binary/test.bytes.csv --tgt-conn postgres --tgt-object public.my_table_bytes
21	Execute SQL command on POSTGRES	1				1	"sling conns exec postgres ""select 1 from ""postgres"".""public"".""my_table_bytes"" where byte_val::bytea::text like '%89504e470d0a1a0a0000000d%'"""
22	Run sling with JSON source and custom columns	2019					SLING_LOADED_AT_COLUMN=false SLING_STREAM_URL_COLUMN=true SLING_ROW_NUM_COLUMN=true sling run --src-stream file://core/dbio/filesys/test/test1/json --tgt-conn postgres --tgt-object public.many_jsons --mode full-refresh
23	Execute SQL command to select distinct stream URL	4				_SLING_STREAM_URL	"sling conns exec postgres ""select distinct _sling_stream_url from public.many_jsons"""
24	Execute SQL command to select stream URL by row number	3				_SLING_STREAM_URL	"sling conns exec postgres ""select _sling_stream_url from public.many_jsons where _sling_row_num = 18"" # should show different file names"
25	Execute SQL command to check column names	2				_sling_row_num|_sling_stream_url	"sling conns exec postgres ""select column_name from information_schema.columns where table_schema = 'public' and table_name = 'many_jsons' and column_name like '_sling%'"" # should not have _sling_loaded_at"
26	Run sling with JSON source and timestamp column	2019					SLING_LOADED_AT_COLUMN='timestamp' sling run --src-stream file://core/dbio/filesys/test/test1/json --tgt-conn postgres --tgt-object public.many_jsons --mode full-refresh
27	Execute SQL command to check data type of timestamp column	1				timestamp with	"sling conns exec postgres ""select data_type from information_schema.columns where table_schema = 'public' and table_name = 'many_jsons' and column_name = '_sling_loaded_at' and data_type like 'timestamp%'"" # _sling_loaded_at should be a timestamp"
28	Test POSTGRES connection					success!	sling conns test POSTGRES
29	Execute SQL command to count rows in POSTGRES table	1				success!|18	sling conns exec POSTGRES 'select count(1) from public.my_table'
30	Discover POSTGRES connections					information_schema	sling conns discover POSTGRES
31	Discover POSTGRES connections with schema filter					information_schema	sling conns discover POSTGRES -s 'public.*'
32	Discover local connections					directory	sling conns discover local -p '.'
33	Discover Prometheus connections with columns				gauge		sling conns discover prometheus --columns
34	Run sling with Prometheus source and custom query					quantile	"sling run --src-conn prometheus --src-stream 'sum(go_gc_duration_seconds) by (job, instance, quantile) # {""start"": ""now-2M""}' --stdout  -d"
35	Run sling with replication configuration 05			12			sling run -r cmd/sling/tests/replications/r.05.yaml
36	Run sling with replication configuration 05 and streams			2			sling run -r cmd/sling/tests/replications/r.05.yaml --streams 's3://ocral/mlo.community.test/channels.json,s3://ocral/mlo.community.test/random/'
37	Run sling with replication configuration 06			3			sling run -r cmd/sling/tests/replications/r.06.yaml
38	Run sling with replication configuration 07			15			sling run -r cmd/sling/tests/replications/r.07.yaml
39	Run sling with replication configuration 08			4			sling run -r cmd/sling/tests/replications/r.08.yaml
40	Run sling with replication configuration 09 and constraints			>1	2		# sling run -r cmd/sling/tests/replications/r.09.yaml
41	Run sling with replication configuration 09			>1		"/ 7] running stream ""public"".""my_table_bytes""|RUNNING"	sling run -d -r cmd/sling/tests/replications/r.09.yaml
42	Run sling with replication configuration 09 and tags			3			sling run -r cmd/sling/tests/replications/r.09.yaml --streams tag:my_table
43	Run sling with replication configuration 10	1018		1		singleFile=true	sling run -d -r cmd/sling/tests/replications/r.10.yaml
44	Run sling with replication configuration 11 and year parameter			2		test1k/2005	YEAR=2005 sling run -r cmd/sling/tests/replications/r.11.yaml
45	Run sling with replication configuration 12			1			sling run -r cmd/sling/tests/replications/r.12.yaml
46	Run sling with replication configuration 15			5		100 rows|[1 / 3] running stream sling_test/lineitem_iceberg	sling run -r cmd/sling/tests/replications/r.15.yaml # iceberg & delta
47	Run sling with replication configuration 15 incremental	>0		1		incremental	ICEBERG_MODE=incremental sling run -r cmd/sling/tests/replications/r.15.yaml --streams sling_test/lineitem_iceberg/
48	Run sling with replication configuration 14			5			sling run -d -r cmd/sling/tests/replications/r.14.yaml
49	Run sling with replication configuration 14	0					sling run -r cmd/sling/tests/replications/r.14.yaml --streams cmd/sling/tests/files/test1.csv,cmd/sling/tests/files/test1.upsert.csv # file incremental. Second run should have no new rows
50	Run sling with replication configuration 16	90		1			sling run -r cmd/sling/tests/replications/r.16.yaml
51	Run sling with task configuration	24					sling run -c cmd/sling/tests/task.yaml
52	Run sling with Parquet source	1018					sling run --src-stream 'file://cmd/sling/tests/files/parquet' --stdout > /dev/null
53	Run sling with empty input	0				execution succeeded	echo '' | sling run --stdout
54	Run sling with CSV source and single quote	3					"sling run --src-conn LOCAL --src-stream file://cmd/sling/tests/files/test7.csv --src-options '{ delimiter: ""|"", quote: ""'\''"", escape: ""\\"" }' --stdout > /dev/null"
55	Run sling with CSV source and $symbol quote	3					"sling run --src-conn LOCAL --src-stream file://cmd/sling/tests/files/test8.csv --src-options '{ delimiter: ""|"", quote: ""$"", escape: ""\\"" }' --stdout > /dev/null"
56	Run sling with direct insert full-refresh	>10		>1		streaming data (direct insert)	SLING_DIRECT_INSERT=true sling run --src-conn postgres --src-stream public.test1k_postgres_pg --tgt-conn mysql --tgt-object 'mysql.public_test1k_postgres_pg' --mode full-refresh
57	Run sling with incremental (delete missing soft)	0				and not exists (	sling run -d --src-conn postgres --src-stream 'select * from public.test1k_postgres_pg where {incremental_where_cond} limit 900' --tgt-conn mysql --tgt-object 'mysql.public_test1k_postgres_pg' --mode incremental --primary-key id --update-key create_dt --tgt-options '{ delete_missing: soft }'
58	Run sling with incremental (delete missing hard)	0				and not exists (	sling run -d --src-conn postgres --src-stream 'select * from public.test1k_postgres_pg where {incremental_where_cond} limit 900' --tgt-conn mysql --tgt-object 'mysql.public_test1k_postgres_pg' --mode incremental --primary-key id --update-key create_dt --tgt-options '{ delete_missing: hard }'
59	Run sling writing to partitioned parquet (local)	1000				partition_by (|create_dt_year=2018	rm -rf /tmp/sling/output8 ; sling run --src-stream file://cmd/sling/tests/files/test1.csv --tgt-object 'file:///tmp/sling/output8/{part_year}/{part_month}' -d --tgt-options '{ format: parquet }' --update-key create_dt ; ls -l /tmp/sling/output8
60	Run sling writing to partitioned parquet (aws)	1002				partition_by (	FORMAT=parquet sling run -d -r cmd/sling/tests/replications/r.17.yaml --mode full-refresh
61	Run sling with incremental writing to partitioned parquet (aws)	40				partition_by (	FORMAT=parquet sling run -d -r cmd/sling/tests/replications/r.17.yaml
62	Run sling writing to partitioned csv (aws)	1002				partition_by (	FORMAT=csv sling run -d -r cmd/sling/tests/replications/r.17.yaml --mode full-refresh
63	Run sling project init					.sling.json	sling project init
64	Run sling project status					PROJECT NAME	sling project status
65	Run sling project jobs					manage project jobs	sling project jobs
66	Run sling project jobs list					FILE NAME	sling project jobs list
67	Run sling hooks & source partitioned (backfill)	551				"executed hook ""start-02"" (type: delete)|writing incremental state (value => 2019-06-01"	RESET=true sling run -r cmd/sling/tests/replications/r.19.yaml -d --mode backfill --range 2018-01-01,2019-05-01
68	Run sling hooks & source partitioned (incremental)	>78				"skipped hook ""start-02""|hook (inspect_file_check) failed => check failure|writing incremental state (value => 2019-07-01"	sling run -r cmd/sling/tests/replications/r.19.yaml -d --streams 'test1k_postgres_pg_parquet'
69	Run sling pipeline 01					"executed step ""step-02"" (type: replication)"	sling run -p cmd/sling/tests/pipelines/p.01.yaml -d
70	Run sling chunking			10		"""update_dt"" >= '2018-11-21|""id"" >= 601 and ""id"" <= 800|TEST1K_SQLSERVER_PG_003|TEST1K_SNOWFLAKE_PG_004"	sling run -r cmd/sling/tests/replications/r.20.yaml -d
71	Run sling pipeline 02					sftp//tmp/test1k_mysql_pg.csv|aws_s3/sling_test/files/test1k_s3.csv	sling run -p cmd/sling/tests/pipelines/p.02.yaml
72	Run sling to test column casing			1		test1k_clickhouse_pg_first_name	sling run -d -r cmd/sling/tests/replications/r.21.yaml
73	Run sling mysql bit			1		execution succeeded	sling run -d -r cmd/sling/tests/replications/r.22.yaml
74	Run sling iceberg insert			2		committed iceberg snapshot	sling run -d -r cmd/sling/tests/replications/r.23.yaml
