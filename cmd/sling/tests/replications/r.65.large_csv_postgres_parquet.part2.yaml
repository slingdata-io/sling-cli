source: POSTGRES
target: LOCAL
# target: LOCAL_PARQUET

hooks:
  start:
    # Clean up any previous output
    - type: command
      command: rm -rf /tmp/data_movement

  end:
    # Check if errored, do not proceed if so
    - type: check
      check: execution.status.error == 0
      on_failure: break

    # Count files generated
    - type: command
      id: file_count
      command: ls -1 /tmp/data_movement/*.parquet | wc -l
      print: false
      capture: true

    - type: log
      message: |
        File count output: {state.file_count.output.combined}
        Trimmed: {trim(state.file_count.output.combined)}

    # Should have created 100 parquet files (1,000,000 / 10,000 = 100)
    - type: check
      check: int_parse(trim(state.file_count.output.combined)) == 101
      success_message: "âœ“ Created 100 parquet files as expected (1M rows / 10K per file)"
      on_failure: break

    # Verify we can read one of the parquet files
    - type: command
      id: file_list
      command: ls -lh /tmp/data_movement/*.parquet | head -5
      print: false
      capture: true

    - type: log
      message: "Sample of generated parquet files:\n{state.file_list.output.combined}"

    # Cleanup
    - type: command
      command: rm -rf /tmp/data_movement

    - type: command
      command: rm -rf /tmp/sling-test-large-data

    - type: query
      connection: '{source.name}'
      query: DROP TABLE IF EXISTS public.stock_movement;

streams:
  public.stock_movement:
    object: file:///tmp/data_movement
    mode: full-refresh
    primary_key: id
    update_key: movement_created_at
    target_options:
      format: parquet
      batch_limit: 500
      file_max_rows: 10000
