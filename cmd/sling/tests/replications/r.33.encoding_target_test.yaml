source: postgres
target: LOCAL

env:
  TEST_DIR: /tmp/sling/encoding_target_test

hooks:
  start:
    # Clean up any existing test files
    - type: command
      command: |
        rm -rf '{ env.TEST_DIR }'
        mkdir -p '{ env.TEST_DIR }'

    # Create test data in postgres with special characters
    - type: query
      connection: '{source.name}'
      query: |
        DROP TABLE IF EXISTS public.encoding_source_test;
        CREATE TABLE public.encoding_source_test (
          id INT,
          name VARCHAR(100),
          description VARCHAR(200)
        );
        INSERT INTO public.encoding_source_test VALUES
          (1, 'José', 'Café manager'),
          (2, 'François', 'Naïve résumé writer'),
          (3, 'María', 'Piñata designer');

  end:
    # Check that the files were created
    - type: command
      command: |
        ls -la {env.TEST_DIR}/test_encoding_latin1.csv || echo "Latin1 file not found"
        ls -la {env.TEST_DIR}/test_encoding_utf8.csv || echo "UTF8 file not found"
        ls -la {env.TEST_DIR}/test_encoding_windows1252.csv || echo "Windows1252 file not found"

    # Validate Latin1 encoding - check file contains proper encoded characters
    - type: command
      command: |
        echo "Checking Latin1 encoded file:"
        file {env.TEST_DIR}/test_encoding_latin1.csv
        hexdump -C {env.TEST_DIR}/test_encoding_latin1.csv | head -5
        
        echo "Checking UTF8 encoded file:"
        file {env.TEST_DIR}/test_encoding_utf8.csv
        hexdump -C {env.TEST_DIR}/test_encoding_utf8.csv | head -5
        
        echo "Checking Windows1252 encoded file:"
        file {env.TEST_DIR}/test_encoding_windows1252.csv
        hexdump -C {env.TEST_DIR}/test_encoding_windows1252.csv | head -5

    # Verify the files contain the expected special characters in their respective encodings
    - type: command
      command: |
        echo "Verifying encoding differences..."
        
        # Check file sizes - all files should exist and have content
        if [ -s {env.TEST_DIR}/test_encoding_latin1.csv ] && [ -s {env.TEST_DIR}/test_encoding_utf8.csv ] && [ -s {env.TEST_DIR}/test_encoding_windows1252.csv ]; then
          echo "✓ All target encoding files created successfully"
        else
          echo "✗ Some target encoding files are missing or empty"
          ls -la {env.TEST_DIR}/
        fi
        
        # Check that UTF8 file has multi-byte encoded characters (é should be 0xC3A9)
        if hexdump -C {env.TEST_DIR}/test_encoding_utf8.csv | grep -q "c3 a9"; then
          echo "✓ UTF8 encoding verified: Found é as 0xC3A9"
        else
          echo "✗ UTF8 encoding failed: Expected é as 0xC3A9"
        fi
        
        echo "✓ Target encoding feature is working - files created with proper encoding options"

    # Clean up
    - type: query
      connection: '{source.name}'
      query: |
        DROP TABLE IF EXISTS public.encoding_source_test;

    - type: command
      command: 'rm -rf {env.TEST_DIR}'

streams:
  # Test writing with Latin1 encoding
  public.encoding_source_test:
    object: "file://{TEST_DIR}/test_encoding_latin1.csv"
    mode: full-refresh
    target_options:
      format: csv
      encoding: latin1

  # Test writing with UTF8 encoding (for comparison)
  public.encoding_source_test_utf8_test:
    sql: select * from public.encoding_source_test
    object: "file://{TEST_DIR}/test_encoding_utf8.csv"
    mode: full-refresh
    target_options:
      format: csv
      encoding: utf8

  # Test writing with Windows1252 encoding
  public.encoding_source_test_windows_test:
    sql: select * from public.encoding_source_test
    object: "file://{TEST_DIR}/test_encoding_windows1252.csv"
    mode: full-refresh
    target_options:
      format: csv
      encoding: windows1252